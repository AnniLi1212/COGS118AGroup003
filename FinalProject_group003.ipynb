{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert title here\n",
    "\n",
    "# Names\n",
    "\n",
    "The Elite Fantasy Team.\n",
    "\n",
    "- Boning Yang (BY)\n",
    "- Chenhao Zhu (CZ)\n",
    "- Jason Chen (JC)\n",
    "- Muchan Li (ML)\n",
    "- Anni Li (AL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "We see thousands of stars hanging up high each night but rarely do we come to wonder about their commonalities and differences. For our project, we decide to train a model to classify each star Morgan-Keenan spectral class by using their unique features. We especially pay attention to the brightness, color, and magnitude of the stars since they are the decisive distinctions. After cleaning the data, we will build two separate models with our dataset–SVC and K Nearest Neighbor algorithm, while paying attention to the accuracy, precision, and recall. We expect to achieve a high classification accuracy ( score above 90) so that we can confidently rely on our model to make convenient yet precise predictions when a new star is observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Since astronomy is a brand new field of wonder to every one of our team, we did a great deal of crash course and factual research in order to better position ourselves to answer the question we came up with.\n",
    "\n",
    "First off, what is the Morgan-Keenan spectral classification system? In short, it is a systematic way introduced by William Wilson Morgan and Philip C. Keenan in 1943 that assigns spectral classification to stars based on their effective temperature. The scale, in descending order, is as follows:\n",
    "- O, >= 30,000 Kelvin,\n",
    "- B, between 10,000 and 30,000 Kelvin\n",
    "- A, between 7,500 and 10,000 Kelvin\n",
    "- F, between 6,000 and 7,500 Kelvin\n",
    "- G, between 5,200 and 6,000 Kelvin\n",
    "- K, between 3,700 and 5,200 Kevlin\n",
    "- M, between 2,400 and 3,700 Kelvin\n",
    "\n",
    "We even found an interesting trick to recite this hierarchy, that is \"**O**h **B**e **A** **F**ine **G**irl (**G**uy), **K**iss **M**e\". More factual information about spectral types and the MK system can be found here<a name=\"MK\"></a>[<sup>[1]</sup>](#MK)\n",
    "\n",
    "Now, some may wonder that since it seems there is a rather obvious connection between stellar temperature and its MK spectral class, why not just scrape the temperature data and match them up? The one apparent objection we've found in regard to this is that the \"temperature\" measurement isn't something that can just be taken for granted (notice that our dataset doesn't have the temperature feature either)--it requires tremendous amount of pre-assumptions, observations, and calculations, and in the end the result one astrophysicist would arrive at may not even be accurate<a name=\"stellartemp\"></a>[<sup>[2]</sup>](#stellartemp). In a more scholarly article<a name=\"infrared\"></a>[<sup>[3]</sup>](#infrared), the authors proposed a revised Infrared Flux method to determine stellar effective temperature with reduced numerical working and further insight into the method. They revisited the assumption that the effective temperature $T_e$ is related to integrated stellar flux and monochromatic stellar flux; combining these two relations, they derived a equation that gives the ratio of integrated stellar flux to monochromatic flux, which also includes the $T_e$ term and can be solved for. However, as they later concluded in the \"Sensitivity and Accuracy of Method\" section, the accuracy of the Infrared Flux method is limited by the accuracy with which the ratio can be measured, which in turn depends on the accuracy of the absolute flux measurements across spectral regions. In a more recent research paper<a name=\"gaia\"></a>[<sup>[4]</sup>](#gaia), in fact, 40 years after the first reference article was published, we are presented with yet another advancement in precise derivation of stellar effective temperature. Nonetheless, the Gaia EDR3 photometry method is still bounded by other measurements and factors like the $K_s$ band, Gaia color, stellar blending, etc. All these prove that \"temperature\" is not a measurement as straightforward as it may seem when it comes to astronomy.\n",
    "\n",
    "Hence, we believe if we are able to use machine learning techniques to \"brute-forcedly\" and reliably classify a star, it would make this classification process more interpretable to astronomy newbies like us and the save the experts a great deal of work all at once when deriving the stellar temperature is not absolutely necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "In this project, we propose to predict the Morgan-Keenan spectral class of a given/newly-observed star using the minimum number of features from a pool of features such as luminosity, absolute visual magnitude, right ascension/declination, etc. while maintaining above 90% accuracy. This problem can be approached by practical machine learning methods such as decision tree, KNN, etc. The result can be evaluated by the accuracy comparing the predicted category and the real category in our training & testing dataset. With correct method and model, this solution should be replicable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "### Dataset name:\n",
    "\n",
    "- hygdata_v3.csv\n",
    "\n",
    "### Github link:\n",
    "\n",
    "- https://github.com/astronexus/HYG-Database\n",
    "\n",
    "### Size of the dataset:\n",
    "\n",
    "- This dataset has 36 variables and 119613 observations. The actual shape of this dataset is 119,614 rows × 37 columns\n",
    "\n",
    "### What an observation consists of:\n",
    "\n",
    "- Each observation contains the location (where the star is located and how far it is) and some critical characteristics of each star, including its brightness, energy, color, etc. There are a total of 36 variables in each observation (some of the variables might not be available) We will use some of the critical variables below to classify star types.\n",
    "\n",
    "### Some critical variables in the dataset:\n",
    "\n",
    "- Spect: The star's spectral type. There are seven main types of stars: OBAFGKM, where O corresponds to the hottest, most powerful stars (and usually the largest) and M corresponds to the coolest, least powerful stars (and usually the smallest). The spectral type of the star will be the labels in our supervised machine learning model.\n",
    "- Distance: The star's distance in parsecs. Distance is one of the traits that we need to consider in our model because the farther away the star is from, the dimmer the star will be. We will need to use distance to more accurately measure the luminosity and the brightness of the stars.\n",
    "- Mag: The star's apparent visual magnitude. We will use the star’s apparent magnitude to determine how bright the star actually is if we observe it from the earth.\n",
    "- AbsMag: The star's absolute visual magnitude, which will be the start’s visual magnitude if we observe 10 parsecs away from the star.  This identity is crucial because it tells us how bright the star “actually” is. If a star’s absolute visual magnitude is high, it is very likely that the star has a large size and high energy.\n",
    "- Ci: The start’s B-V color index. This index will indicate the star’s color, which will be an efficient way to indicate the star’s temperature and energy. It is defined as the difference between the blue magnitude and the star’s visual magnitude. The larger the B-V color index, the higher temperature the star will be at (and also, the star will appear bluer)\n",
    "- Lum: The star's luminosity. This variable is defined by the total electromagnetic power emitted by the star in a given time, and it is shown as a multiple of the solar luminosity (where the sun’s luminosity will be defined as 1). The higher the luminosity the star is, the more energy it will release in a given time period. In other words, the higher the luminosity, the more powerful the star is.\n",
    "\n",
    "### Any special handling, transformations, cleaning, etc will be needed:\n",
    "\n",
    "- This dataset contains some variables that we will not be used in classification so we will clean the data to make sure we only have the data we need. Also, the star’s spectral type contains a subtype for each class. For example, in class F, we might have F5 or F0V, etc. We will also clean the data so that we only use the general type to classify star type in order to reduce model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Here's the dataset:\n",
    "import pandas as pd\n",
    "\n",
    "HYG = pd.read_csv('hygdata_v3.csv')\n",
    "HYG.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Here are the packages we will use\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- First, we will use pandas packages to import, clean, and modify our dataset\n",
    "- Second, we will use data balancing functions from skleanr.metrics to balance our data\n",
    "- Third, we will use train-test split and KFold functions from skleanrn.model_selection to carry out train-test dataset split and cross validation\n",
    "- Fourth, we will train our decision tree classifier and KNN model with optimal parameters using the sklearn.tree and sklearn.neighbors\n",
    "- Fifth, we will test our model against the test set and obtain test metrics using sklearn.metrics\n",
    "- Sixth, we will use plotting methods from seaborn and matplotlib to visualize our testing metrics and confusion matrices\n",
    "- Seventh, we will repeat the above model training pipeline to prune and optimize for models with simpler features, i.e. less splits, shallower depth, less neighbors.\n",
    "\n",
    "Finally, alongside these 7 general step procedures of model training, we will build a grid search pipeline at each stage of our model (where a stage in our design refers to a model trained using a certain number of parameters) until we arrive at one that is the simplest yet still accurately (above 90% accuracy score) captures the information. It is also important to note that we will not aim for exhaustively trialing out all combinations of features to our model (i.e. listing all combinations of 3 out of 10 features and tuning the best model for each), we instead aim to construct one that is most intuitive and easy to visualize."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "For our KNN classifier, we would like to use accuracy and precision to determine how good our model is. Specifically, we would like to use sklearn.metrics.accuracy_score and sklearn.metrics.average_precision_score to evaluate the performance of our model.\n",
    "\n",
    "Accuracy indicates how many correct data points we can get from the overall data set. This is an important factor to help us to evaluate our training model. The way the accuracy is defined is by using true positives and true negatives divided by the number of true positives, true negatives, false positives, and false negatives. The equation is shown below:\n",
    "\n",
    "$ {Accuracy} = \\frac {True Positives + True Negatives}{True Positives + True Negatives + False Positives + False Negatives} $\n",
    "\n",
    "We want our accuracy as high as possible because the higher the accuracy, the better our classifier can make the right classifications.\n",
    "\n",
    "Precision is the quality of the positive prediction generated by the training model. It refers to the number of true positives divided by the total number of positive predictions. The equation is shown below:\n",
    "\n",
    "$ {Precision} = \\frac {True Positives}{True Positives + False Positives} $\n",
    "\n",
    "We also want our precision as high as possible because the higher our precision, the lower the chance the classifier can make false positive results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Subsection 1\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "### Ethics & Privacy\n",
    "Since we are doing all the work related to star and astronomy, our project will not relate to any people or society. We do not need informed consent since we don’t have an object to be consent. All our data are from astronomy institution, and we will not collect any data through collection or survey which means we will not have collection bias. We also don’t have PII exposure issue and don’t need to consider downstream bias mitigation since we are not dealing with data related to human.\n",
    "\n",
    "Data storage:\n",
    "We all get the data source from open source, but all these sources have their own copyright. We will use proper citation to give credit to those institutions who provides these valuable data. We will also follow the guideline with the right to be forgotten. If any institutions delete their data or made their data private during our project, we will need to remove their data. We have several datasets which could be used in this project so we already have a data retention plan.\n",
    "\n",
    "Analysis:\n",
    "We will make sure our data analysis will avoid data bias and our result will be honest representation of the dataset. We will keep our analysis private to protect the privacy of original dataset.\n",
    "\n",
    "Modeling:\n",
    "We will not have proxy discrimination issue since astronomy data will not have any unfairly discriminatory. We will choose best metric to optimizing our defined metrics and we will explain why we made the decision of the model.\n",
    "\n",
    "Deployment:\n",
    " We will not have redress problem since we are not dealing with human participants. We will make our model able to roll back when necessary, we will also test our concept to make sure that our model with no bias or little bias. We will made this project private to avoid unintended use.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"MK\"></a>1.[^](#MK): https://starparty.com/topics/astronomy/stars/the-morgan-keenan-system/<br>\n",
    "<a name=\"stellartemp\"></a>2.[^](#stellartemp): https://www.secretsofuniverse.in/measuring-temperature-of-stars/<br>\n",
    "<a name=\"stellartemp\"></a>3.[^](#infrared): Blackwell, D. E., Petford, A. D., & Shallis, M. J. (1980). Use of the infra-red flux method for determining stellar effective temperatures and angular diameters-The stellar temperature scale. Astronomy and Astrophysics, 82, 249-252.<br>\n",
    "<a name=\"gaia\"></a>4.[^](#gaia): Mucciarelli, A., Bellazzini, M., & Massari, D. (2021). Exploiting the Gaia EDR3 photometry to derive stellar temperatures. Astronomy & Astrophysics, 653, A90.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}